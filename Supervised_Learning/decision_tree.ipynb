{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier - From Scratch\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "You are given a very simple dataset that classifies drinks into three types: **Wine**, **Beer**, and **Whiskey**, based on their **alcohol content**, **sugar content**, and **color**. Your job is to build a **Decision Tree Classifier** that predicts the type of drink given its features.\n",
    "\n",
    "## Load and Pre-process the Data\n",
    "\n",
    "Alright, let's first load up the data into a NumPy matrix and split it into feature vectors and target labels, and also apply some ordinal encoding on the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12. ,  1.5,  1. ],\n",
       "       [ 5. ,  2. ,  0. ],\n",
       "       [40. ,  0. ,  1. ],\n",
       "       [13.5,  1.2,  1. ],\n",
       "       [ 4.5,  1.8,  0. ],\n",
       "       [38. ,  0.1,  1. ],\n",
       "       [11.5,  1.7,  1. ],\n",
       "       [ 5.5,  2.3,  0. ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = [\n",
    "    [12.0, 1.5, 1, 'Wine'],\n",
    "    [5.0, 2.0, 0, 'Beer'],\n",
    "    [40.0, 0.0, 1, 'Whiskey'],\n",
    "    [13.5, 1.2, 1, 'Wine'],\n",
    "    [4.5, 1.8, 0, 'Beer'],\n",
    "    [38.0, 0.1, 1, 'Whiskey'],\n",
    "    [11.5, 1.7, 1, 'Wine'],\n",
    "    [5.5, 2.3, 0, 'Beer']\n",
    "]\n",
    "\n",
    "def preprocess_data(df):\n",
    "    encoding = {'Wine':0,'Beer':1,'Whiskey':2}\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for row in df:\n",
    "        X.append(row[:-1])\n",
    "        y.append(encoding[row[3]])\n",
    "\n",
    "    return np.array(X),np.array(y)\n",
    "\n",
    "X, y = preprocess_data(data)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini Impurity and Best Split\n",
    "\n",
    "### Gini Impurity\n",
    "\n",
    "We'll use **Gini Impurity** as the metric for splitting the dataset. The Gini Impurity is the probability of a new random point being misclassified according to the current distribution. Mathematically, the Gini Impurity of a dataset $D$ can is written as:\n",
    "\n",
    "$Gini(D) = 1 - \\sum_{i=1}^k p_i^2$\n",
    "\n",
    "Where $k$ is the number of unique classes in $D$ and $p_i$ is the probability of a sample in $D$ belonging to class $i$.\n",
    "\n",
    "If $D$ of size $n$ is split into $D_1$ and $D_2$ of sizes $n_1$ and $n_2$, the Gini Impurity can be defined as:\n",
    "\n",
    "$Gini(D) = \\frac{n_1}{n} Gini(D_1) + \\frac{n_2}{n} Gini(D_2)$\n",
    "\n",
    "### Best Split\n",
    "\n",
    "To split the data, we will require a feature and the threshold value for that feature. In order to do this, we will do the following:\n",
    "\n",
    "1. Iterate through all the feature vectors.\n",
    "\n",
    "2. For each feature vector, iterate through all threshold values. The threshold values I am using will be the midpoint between two consecutive values in the sorted feature vector. So, for a feature vector $V = \\{v_1,v_2,\\dots ,v_m\\}$, the thresholds will be $\\frac{v_i + v_{i+1}}{2}$, where $i=1,2,\\dots ,m$\n",
    "\n",
    "3. Return the feature and threshold combination which gives the least Gini Impurity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_impurity(y):\n",
    "    counts = {label:0 for label in set(y)}\n",
    "    for y_i in y:\n",
    "        counts[y_i] += 1\n",
    "    n = len(y)\n",
    "\n",
    "    impurity = 1\n",
    "    for label,count in counts.items():\n",
    "        impurity -= ((count/n)**2)\n",
    "\n",
    "    return impurity\n",
    "\n",
    "def return_best_split_gini(X,y):\n",
    "    min_impurity = -1\n",
    "    best_feature_index = None\n",
    "    best_threshold = None\n",
    "\n",
    "    m,n = X.shape\n",
    "    for feature_index in range(n):\n",
    "        feature_vector = X[:,feature_index]\n",
    "        feature_vector = np.sort(feature_vector)\n",
    "        for i in range(m-1):\n",
    "            threshold = (feature_vector[i] + feature_vector[i+1])/2\n",
    "            left_split = []\n",
    "            right_split = []\n",
    "\n",
    "            for j in range(m):\n",
    "                if(X[j][feature_index] < threshold):\n",
    "                    left_split.append(y[j])\n",
    "                else:\n",
    "                    right_split.append(y[j])\n",
    "\n",
    "            impurity = len(left_split)/m * gini_impurity(left_split) + len(right_split)/m * gini_impurity(right_split)\n",
    "            if min_impurity==-1 or (impurity < min_impurity):\n",
    "                min_impurity = impurity\n",
    "                best_feature_index = feature_index\n",
    "                best_threshold = threshold\n",
    "\n",
    "    return best_feature_index, best_threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Recursive Tree Building\n",
    "\n",
    "Defined below is the class `Node`, which has the following attributes:\n",
    "- `feature_index` : Stores best feature index for splitting.\n",
    "- `threshold` : Threshold value for splitting.\n",
    "- `left` : Left child node.\n",
    "- `right` : Right child node.\n",
    "- `value` : Majority class label if leaf node.\n",
    "- `min_samples_split` : Least number of samples required to split the Node further.\n",
    "\n",
    "We also take a `max_depth` argument to limit the number of splits.\n",
    "\n",
    "We directly initialise the object with $X$ and $y$ and it starts the splitting process by obtaining the best feauture and threshold, and then recursively splitting the child nodes until we reach leaf nodes.\n",
    "\n",
    "Of course, a separate function can be made for fitting the data as is usually used, but this works too (I suppose).\n",
    "\n",
    "Prediction is done by recursively taversing the tree until a leaf node is reached, where the value of the node is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "\n",
    "    def __init__(self,X,y,max_depth=1):\n",
    "        self.feature_index = None\n",
    "        self.threshold = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.value = None\n",
    "        self.min_samples_split = 2\n",
    "\n",
    "        m,_ = X.shape\n",
    "        if len(np.unique(y))==1 or max_depth == 0 or m < self.min_samples_split:\n",
    "            freqs = {label:0 for label in set(y)}\n",
    "            max_freq = 0\n",
    "            for i in range(m):\n",
    "                freqs[y[i]] += 1\n",
    "\n",
    "                if freqs[y[i]] > max_freq:\n",
    "                    max_freq = freqs[y[i]]\n",
    "                    self.value = y[i]\n",
    "\n",
    "        else:\n",
    "            self.feature_index, self.threshold = return_best_split_gini(X,y)\n",
    "\n",
    "            left_X, left_y = [], []\n",
    "            right_X, right_y = [], []\n",
    "            m,_ = X.shape\n",
    "\n",
    "            for i in range(m):\n",
    "                if X[i][self.feature_index] < self.threshold:\n",
    "                    left_X.append(X[i])\n",
    "                    left_y.append(y[i])\n",
    "                else:\n",
    "                    right_X.append(X[i])\n",
    "                    right_y.append(y[i])\n",
    "            \n",
    "            self.left = Node(np.array(left_X),np.array(left_y),max_depth-1)\n",
    "            self.right = Node(np.array(right_X), np.array(right_y),max_depth-1)\n",
    "\n",
    "    def predict(self,X):\n",
    "        preds = []\n",
    "        m,_ = X.shape\n",
    "        if self.value == None:\n",
    "            \n",
    "            for i in range(m):\n",
    "                if X[i][self.feature_index] < self.threshold:\n",
    "                    preds.append(self.left.predict(X[i].reshape(1,-1))[0])\n",
    "                else:\n",
    "                    preds.append(self.right.predict(X[i].reshape(1,-1))[0])\n",
    "\n",
    "        else:\n",
    "\n",
    "            preds = [self.value] * m\n",
    "        \n",
    "        return np.array(preds)\n",
    "    \n",
    "    def print_tree(self, depth=0):\n",
    "        indent = \"  \" * depth\n",
    "        if self.value is not None:\n",
    "            print(f\"{indent}Return {self.value}\")\n",
    "        else:\n",
    "            print(f\"{indent}Feature[{self.feature_index}] < {self.threshold:.3f}?\")\n",
    "            if self.left:\n",
    "                print(f\"{indent}--> True:\")\n",
    "                self.left.print_tree(depth + 1)\n",
    "            if self.right:\n",
    "                print(f\"{indent}--> False:\")\n",
    "                self.right.print_tree(depth + 1)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Alright! Let's now test the data against a simple test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beer' 'Whiskey' 'Wine']\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([\n",
    "    [6.0, 2.1, 0],   # Expected: Beer\n",
    "    [39.0, 0.05, 1], # Expected: Whiskey\n",
    "    [13.0, 1.3, 1]   # Expected: Wine\n",
    "])\n",
    "\n",
    "tree = Node(X,y,10)\n",
    "\n",
    "def show_actual_pred(X):\n",
    "    encoding = {0:'Wine',1:'Beer',2:'Whiskey'}\n",
    "    preds = tree.predict(X)\n",
    "\n",
    "    return np.array([encoding[pred] for pred in preds])\n",
    "\n",
    "print(show_actual_pred(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to work just fine!\n",
    "\n",
    "\n",
    "# Bonus Tasks!\n",
    "\n",
    "## Print the Tree in a Pretty Format\n",
    "\n",
    "Alright, let's get to it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature[0] < 8.500?\n",
      "--> True:\n",
      "  Return 1\n",
      "--> False:\n",
      "  Feature[0] < 25.750?\n",
      "  --> True:\n",
      "    Return 0\n",
      "  --> False:\n",
      "    Return 2\n"
     ]
    }
   ],
   "source": [
    "# Already implemted the method in the Node class!\n",
    "tree.print_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Entropy instead of Gini as the Metric\n",
    "\n",
    "Entropy for a dataset $D$ with $k$ classes and $p_i$ being the probability of a label belonging to class $i$ is defined as:\n",
    "\n",
    "Entropy($D$) $= -\\sum_{i=1}^k p_i log_2 (pi)$\n",
    "\n",
    "So Entropy for a class split would be:\n",
    "\n",
    "Entropy($D$) = $\\frac{n_1}{n}$ Entropy($D_1$) + $\\frac{n_2}{n}$ Entropy($D_2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    labels, counts = np.unique(y, return_counts=True)\n",
    "    probs = counts / len(y)\n",
    "    return -np.sum(probs * np.log2(probs))\n",
    "\n",
    "\n",
    "def return_best_split_ent(X,y):\n",
    "    min_impurity = -1\n",
    "    best_feature_index = None\n",
    "    best_threshold = None\n",
    "\n",
    "    m,n = X.shape\n",
    "    for feature_index in range(n):\n",
    "        feature_vector = X[:,feature_index]\n",
    "        feature_vector = np.sort(feature_vector)\n",
    "        for i in range(m-1):\n",
    "            threshold = (feature_vector[i] + feature_vector[i+1])/2\n",
    "            left_split = []\n",
    "            right_split = []\n",
    "\n",
    "            for j in range(m):\n",
    "                if(X[j][feature_index] < threshold):\n",
    "                    left_split.append(y[j])\n",
    "                else:\n",
    "                    right_split.append(y[j])\n",
    "\n",
    "            impurity = len(left_split)/m * entropy(left_split) + len(right_split)/m * entropy(right_split)\n",
    "            if min_impurity==-1 or (impurity < min_impurity):\n",
    "                min_impurity = impurity\n",
    "                best_feature_index = feature_index\n",
    "                best_threshold = threshold\n",
    "\n",
    "    return best_feature_index, best_threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's redefine our class and test it.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beer' 'Whiskey' 'Wine']\n"
     ]
    }
   ],
   "source": [
    "class Node:\n",
    "\n",
    "    def __init__(self,X,y,max_depth=1):\n",
    "        self.feature_index = None\n",
    "        self.threshold = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.value = None\n",
    "        self.min_samples_split = 2\n",
    "\n",
    "        m,_ = X.shape\n",
    "        if len(np.unique(y))==1 or max_depth == 0 or m < self.min_samples_split:\n",
    "            freqs = {label:0 for label in set(y)}\n",
    "            max_freq = 0\n",
    "            for i in range(m):\n",
    "                freqs[y[i]] += 1\n",
    "\n",
    "                if freqs[y[i]] > max_freq:\n",
    "                    max_freq = freqs[y[i]]\n",
    "                    self.value = y[i]\n",
    "\n",
    "        else:\n",
    "            self.feature_index, self.threshold = return_best_split_ent(X,y)\n",
    "\n",
    "            left_X, left_y = [], []\n",
    "            right_X, right_y = [], []\n",
    "            m,_ = X.shape\n",
    "\n",
    "            for i in range(m):\n",
    "                if X[i][self.feature_index] < self.threshold:\n",
    "                    left_X.append(X[i])\n",
    "                    left_y.append(y[i])\n",
    "                else:\n",
    "                    right_X.append(X[i])\n",
    "                    right_y.append(y[i])\n",
    "            \n",
    "            self.left = Node(np.array(left_X),np.array(left_y),max_depth-1)\n",
    "            self.right = Node(np.array(right_X), np.array(right_y),max_depth-1)\n",
    "\n",
    "    def predict(self,X):\n",
    "        preds = []\n",
    "        m,_ = X.shape\n",
    "        if self.value == None:\n",
    "            \n",
    "            for i in range(m):\n",
    "                if X[i][self.feature_index] < self.threshold:\n",
    "                    preds.append(self.left.predict(X[i].reshape(1,-1))[0])\n",
    "                else:\n",
    "                    preds.append(self.right.predict(X[i].reshape(1,-1))[0])\n",
    "\n",
    "        else:\n",
    "\n",
    "            preds = [self.value] * m\n",
    "        \n",
    "        return np.array(preds)\n",
    "    \n",
    "    def print_tree(self, depth=0):\n",
    "        indent = \"  \" * depth\n",
    "        if self.value is not None:\n",
    "            print(f\"{indent}Return {self.value}\")\n",
    "        else:\n",
    "            print(f\"{indent}Feature[{self.feature_index}] < {self.threshold:.3f}?\")\n",
    "            if self.left:\n",
    "                print(f\"{indent}--> True:\")\n",
    "                self.left.print_tree(depth + 1)\n",
    "            if self.right:\n",
    "                print(f\"{indent}--> False:\")\n",
    "                self.right.print_tree(depth + 1)\n",
    "\n",
    "test_data = np.array([\n",
    "    [6.0, 2.1, 0],   # Expected: Beer\n",
    "    [39.0, 0.05, 1], # Expected: Whiskey\n",
    "    [13.0, 1.3, 1]   # Expected: Wine\n",
    "])\n",
    "\n",
    "tree = Node(X,y,10)\n",
    "\n",
    "def show_actual_pred(X):\n",
    "    encoding = {0:'Wine',1:'Beer',2:'Whiskey'}\n",
    "    preds = tree.predict(X)\n",
    "\n",
    "    return np.array([encoding[pred] for pred in preds])\n",
    "\n",
    "print(show_actual_pred(test_data))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works!!\n",
    "\n",
    "And I guess that concludes this task!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
